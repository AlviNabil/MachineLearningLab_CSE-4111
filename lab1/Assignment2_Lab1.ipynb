{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing all the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kNN.simple_KNN import simpleKNN\n",
    "from sklearn.metrics import accuracy_score #only to check accuracy for the first time with a defined k value\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read The Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for google colab \n",
    "# ========>>========>>=========>>========>>\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# pima = pd.read_csv('/content/drive/MyDrive/4_1/ML/lab1/data/iris.csv')\n",
    "# ==========>>=========>>===========>>==========>>\n",
    "\n",
    "\n",
    "#for local\n",
    "# fileName = str(input(\"Enter File Name: \"))\n",
    "fileName = \"iris.csv\"\n",
    "data = pd.read_csv(\"../data/\"+fileName)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Getting all the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "for i in data.columns:\n",
    "    column_names.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visualizing the effects of various features on output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    if data.iloc[i][data.shape[1]-1]==\"Setosa\":\n",
    "        data.iloc[i,data.shape[1]-1]=0\n",
    "    elif data.iloc[i][data.shape[1]-1]==\"Versicolor\":\n",
    "        data.iloc[i,data.shape[1]-1]=1\n",
    "    else :\n",
    "        data.iloc[i,data.shape[1]-1]=2\n",
    "print(data.head())\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(fileName)\n",
    "plt.scatter(data.iloc[:,0], data.iloc[:,1], c=data.iloc[:, data.shape[1]-1])\n",
    "plt.xlabel(\"Sepal Length\")\n",
    "plt.ylabel(\"Sepal Width\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(fileName)\n",
    "plt.scatter(data.iloc[:,2], data.iloc[:,3], c=data.iloc[:, data.shape[1]-1])\n",
    "plt.xlabel(\"Petal Length\")\n",
    "plt.ylabel(\"Petal Width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Randomly Splitting out dataset into training data and test data depending on split ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "pd.options.mode.chained_assignment = None \n",
    "trainSet = pd.DataFrame(columns=column_names[0:len(column_names)])\n",
    "testSet = pd.DataFrame(columns=column_names[0:len(column_names)])\n",
    "def  loadDataSet(data, split, train, test):\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]-1):\n",
    "            data.loc[i][j]=float(data.loc[i][j])\n",
    "        if random.random()<split:\n",
    "            train.loc[train.shape[0]] = data.iloc[i].values\n",
    "        else:\n",
    "            test.loc[test.shape[0]] = data.iloc[i].values\n",
    "loadDataSet(data, .8, trainSet, testSet)\n",
    "print(trainSet.shape)\n",
    "print(testSet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Separating TrainFeatures from TrainTargets and TestFeatures from TestTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatures = trainSet.iloc[:,0:trainSet.shape[1]-1]\n",
    "trainTargets = trainSet.iloc[:, trainSet.shape[1]-1:trainSet.shape[1]]\n",
    "testFeatures = testSet.iloc[:, 0:testSet.shape[1]-1]\n",
    "testTargets = testSet.iloc[:, testSet.shape[1]-1:testSet.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Applying implemented kNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = simpleKNN(k_neighbors=3)\n",
    "kn.fit(trainFeatures, trainTargets)\n",
    "prediction = kn.predict(testFeatures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Testing the accuracy of the implemented algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTargetList = testTargets['variety'].tolist()\n",
    "print(prediction)\n",
    "print(testTargetList)\n",
    "print(\"Accuracy: \", accuracy_score(testTargetList,prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Storing error percentage for different k value from 1 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(1,50):\n",
    "    kn = simpleKNN(k_neighbors=i)\n",
    "    kn.fit(trainFeatures, trainTargets)\n",
    "    prediction = kn.predict(testFeatures)\n",
    "    testTargetList = testTargets['variety'].tolist()\n",
    "    prediction = np.array(prediction)\n",
    "    testTargetList = np.array(testTargetList)\n",
    "    error.append(np.mean(prediction!=testTargetList))\n",
    "    # print(\"Accuracy: \", accuracy_score(prediction, testTargetList))\n",
    "    print(i,\"==>error percentage:\",np.mean(prediction!=testTargetList)*100,\"% \\tNumber of Error: \",int(np.mean(prediction!=testTargetList)*len(testTargetList)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Plotting Mean Error vs k-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "ax=plt.axes()\n",
    "ax.set(facecolor=\"#D5D8DC\")\n",
    "plt.plot(\n",
    "    range(1, 50), \n",
    "    error, \n",
    "    color='#2E4053',\n",
    "    linestyle='dashed', \n",
    "    marker='o', \n",
    "    markerfacecolor='#8E44AD', \n",
    "    markersize=10\n",
    ")\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K Values')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Finding the best value of k for our data which is for minimum error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best K value \", np.argmin(error)+1, \"The minimum error value is :\", min(error),\"\\n(If multiple first one is taken)\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c7e68624cde4f8d6e1e9b7994c00422121a518a4e6de628e1935b5e03ecb62e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
